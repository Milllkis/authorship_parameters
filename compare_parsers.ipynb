{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5okpFpTHDmze",
        "ozasw_2NgVgP",
        "AnY2ZpRiga76",
        "VNunLXWggcgb",
        "7RZIy8hAxQzl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqNL6NS4jSMO"
      },
      "source": [
        "#### Сравнение парсеров для русского языка"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Подготавливаем файл для сравнения"
      ],
      "metadata": {
        "id": "5okpFpTHDmze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-Taiga/master/ru_taiga-ud-test.conllu"
      ],
      "metadata": {
        "id": "Qv_B_kckhFrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = []\n",
        "\n",
        "with open(\"ru_taiga-ud-test.conllu\", \"r\", encoding=\"utf-8\") as data_file:\n",
        "    data_file = data_file.readlines()\n",
        "    for line in data_file:\n",
        "        if '# text' in line:\n",
        "            test_sentences.append(line[9:].strip())"
      ],
      "metadata": {
        "id": "-2--W1ipm9N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXRAG_AYoW6-",
        "outputId": "f31c5318-496c-4fb3-c94c-6630504bc64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "881"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"ru_taiga-ud-test.conllu\", \"r\", encoding=\"utf-8\") as data_file:\n",
        "    with open(\"test.conllu\", \"w\", encoding=\"utf-8\") as test_file:\n",
        "        data_file = data_file.readlines()\n",
        "        for line in data_file:\n",
        "            if '# sent' in line:\n",
        "                continue\n",
        "            elif '# genre' in line:\n",
        "                continue\n",
        "            elif '# new' in line:\n",
        "                continue\n",
        "            elif line == \"\\n\":\n",
        "                print('\\n', file=test_file)\n",
        "            else:\n",
        "                print(line.strip(), file=test_file)"
      ],
      "metadata": {
        "id": "Md0d7FTR1y7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### UdPipe"
      ],
      "metadata": {
        "id": "ozasw_2NgVgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ufal.udpipe\n",
        "!pip install conllu\n",
        "!wget https://github.com/jwijffels/udpipe.models.ud.2.5/raw/master/inst/udpipe-ud-2.5-191206/russian-syntagrus-ud-2.5-191206.udpipe"
      ],
      "metadata": {
        "id": "GmjwR_GrgfR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "import ufal.udpipe\n",
        "import conllu\n",
        "from collections import defaultdict\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "MPWMQEzTgroJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, path):\n",
        "        \"\"\"Load given model.\"\"\"\n",
        "        self.model = ufal.udpipe.Model.load(path)\n",
        "        if not self.model:\n",
        "            raise Exception(\"Cannot load UDPipe model from file '%s'\" % path)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Tokenize the text and return list of ufal.udpipe.Sentence-s.\"\"\"\n",
        "        tokenizer = self.model.newTokenizer(self.model.DEFAULT)\n",
        "        if not tokenizer:\n",
        "            raise Exception(\"The model does not have a tokenizer\")\n",
        "        return self._read(text, tokenizer)\n",
        "\n",
        "    def read(self, text, in_format):\n",
        "        \"\"\"Load text in the given format (conllu|horizontal|vertical) and return list of ufal.udpipe.Sentence-s.\"\"\"\n",
        "        input_format = ufal.udpipe.InputFormat.newInputFormat(in_format)\n",
        "        if not input_format:\n",
        "            raise Exception(\"Cannot create input format '%s'\" % in_format)\n",
        "        return self._read(text, input_format)\n",
        "\n",
        "    def _read(self, text, input_format):\n",
        "        input_format.setText(text)\n",
        "        error = ufal.udpipe.ProcessingError()\n",
        "        sentences = []\n",
        "\n",
        "        sentence = ufal.udpipe.Sentence()\n",
        "        while input_format.nextSentence(sentence, error):\n",
        "            sentences.append(sentence)\n",
        "            sentence = ufal.udpipe.Sentence()\n",
        "        if error.occurred():\n",
        "            raise Exception(error.message)\n",
        "\n",
        "        return sentences\n",
        "\n",
        "    def tag(self, sentence):\n",
        "        \"\"\"Tag the given ufal.udpipe.Sentence (inplace).\"\"\"\n",
        "        self.model.tag(sentence, self.model.DEFAULT)\n",
        "\n",
        "    def parse(self, sentence):\n",
        "        \"\"\"Parse the given ufal.udpipe.Sentence (inplace).\"\"\"\n",
        "        self.model.parse(sentence, self.model.DEFAULT)\n",
        "\n",
        "    def write(self, sentences, out_format):\n",
        "        \"\"\"Write given ufal.udpipe.Sentence-s in the required format (conllu|horizontal|vertical).\"\"\"\n",
        "\n",
        "        output_format = ufal.udpipe.OutputFormat.newOutputFormat(out_format)\n",
        "        output = ''\n",
        "        for sentence in sentences:\n",
        "            output += output_format.writeSentence(sentence)\n",
        "        output += output_format.finishDocument()\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "dEAeHCUdtOlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model('/content/russian-syntagrus-ud-2.5-191206.udpipe')"
      ],
      "metadata": {
        "id": "iNLVNfKBgyb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conllu(model, text):\n",
        "    sentences = model.tokenize(text)\n",
        "    for s in sentences:\n",
        "        model.tag(s)\n",
        "        model.parse(s)\n",
        "    conllu_text = model.write(sentences, \"conllu\")\n",
        "    return conllu_text"
      ],
      "metadata": {
        "id": "yLid3K2_g0pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"udpipe.conllu\", \"w\", encoding=\"utf-8\") as output_file:\n",
        "    for sentence in test_sentences:\n",
        "        udpipe_results = get_conllu(model, test_sentences[0])\n",
        "        print(udpipe_results[32:], file=output_file)"
      ],
      "metadata": {
        "id": "vmatsQW-g3g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Spacy"
      ],
      "metadata": {
        "id": "AnY2ZpRiga76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!pip install https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.1.0/ru_core_news_sm-3.1.0.tar.gz\n",
        "!pip install spacy_conll"
      ],
      "metadata": {
        "id": "7UbjD0fnpdxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy_conll import init_parser\n",
        "\n",
        "nlp_spacy = init_parser(\"ru_core_news_sm\",\n",
        "                  \"spacy\",\n",
        "                  ext_names={\"conll_str\": \"conll_str\"})\n",
        "\n",
        "with open('spacy.conllu', 'w', encoding='UTF-8') as out:\n",
        "    for sent in test_sentences:\n",
        "        doc = nlp_spacy(sent)\n",
        "        out.write(f'# text = {sent}\\n')\n",
        "        out.write(doc._.conll_str)\n",
        "        out.write('\\n\\n')"
      ],
      "metadata": {
        "id": "k8AabJPjqW_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Stanza"
      ],
      "metadata": {
        "id": "VNunLXWggcgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza\n",
        "!pip install spacy-stanza"
      ],
      "metadata": {
        "id": "oPWxPrqarmSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "import spacy_stanza\n",
        "from spacy_conll import init_parser\n",
        "\n",
        "nlp_stanza = init_parser(\"ru\",\n",
        "                  \"stanza\",\n",
        "                  ext_names={\"conll_str\": \"conll_str\"})\n",
        "\n",
        "\n",
        "with open('stanza.conllu', 'w', encoding='UTF-8') as out:\n",
        "    for sent in test_sentences:\n",
        "        doc = nlp_stanza(sent)\n",
        "        out.write(f'# text = {sent}\\n')\n",
        "        out.write(doc._.conll_str)\n",
        "        out.write('\\n\\n')"
      ],
      "metadata": {
        "id": "LNaO0IF-uUMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Собственно сравнение"
      ],
      "metadata": {
        "id": "7RZIy8hAxQzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conllu(file_path):\n",
        "    blocks = []\n",
        "    data = []\n",
        "    current_block = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            if line.startswith(\"# text\"):\n",
        "                if current_block:\n",
        "                    data.append(current_block)\n",
        "                    current_block = []\n",
        "                current_block.append(line)\n",
        "            elif line != \"\\n\":\n",
        "                current_block.append(line)\n",
        "\n",
        "        if current_block:\n",
        "            data.append(current_block)\n",
        "\n",
        "    for block in data:\n",
        "        chain = []\n",
        "        for line in block:\n",
        "            if '# text' not in line:\n",
        "                chain.append(line.strip().split(\"\\t\"))\n",
        "        blocks.append(chain)\n",
        "    return blocks"
      ],
      "metadata": {
        "id": "hhDhG0GJmV2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_conllu_files(file_path1, file_path2):\n",
        "    test = read_conllu(file_path1)\n",
        "    data = read_conllu(file_path2)\n",
        "\n",
        "    FORM_total = 0\n",
        "    form = 0\n",
        "    LEMMA_total = 0\n",
        "    lemma = 0\n",
        "    UPOS_total = 0\n",
        "    upos = 0\n",
        "    XPOS_total = 0\n",
        "    xpos = 0\n",
        "    FEATS_total = 0\n",
        "    feats = 0\n",
        "    HEAD_total = 0\n",
        "    head = 0\n",
        "    DEPREL_total = 0\n",
        "    deprel = 0\n",
        "\n",
        "    for n, block in enumerate(test):\n",
        "        if len(block) <= len(data[n]):\n",
        "            for i in range(len(block)):\n",
        "                FORM_total += 1\n",
        "                LEMMA_total += 1\n",
        "                UPOS_total += 1\n",
        "                XPOS_total += 1\n",
        "                FEATS_total += 1\n",
        "                HEAD_total += 1\n",
        "                DEPREL_total += 1\n",
        "                if data[n][i][1] == block[i][1]:\n",
        "                    form +=1\n",
        "                if data[n][i][2] == block[i][2]:\n",
        "                    lemma +=1\n",
        "                if data[n][i][3] == block[i][3]:\n",
        "                    upos +=1\n",
        "                if data[n][i][4] == block[i][4]:\n",
        "                    xpos +=1\n",
        "                if data[n][i][5] == block[i][5]:\n",
        "                    feats +=1\n",
        "                if data[n][i][6] == block[i][6]:\n",
        "                    head +=1\n",
        "                if data[n][i][7] == block[i][7]:\n",
        "                    deprel +=1\n",
        "        if len(block) > len(data[n]):\n",
        "            for i in range(len(data[n])):\n",
        "                FORM_total += 1\n",
        "                LEMMA_total += 1\n",
        "                UPOS_total += 1\n",
        "                XPOS_total += 1\n",
        "                FEATS_total += 1\n",
        "                HEAD_total += 1\n",
        "                DEPREL_total += 1\n",
        "                if data[n][i][1] == block[i][1]:\n",
        "                    form +=1\n",
        "                if data[n][i][2] == block[i][2]:\n",
        "                    lemma +=1\n",
        "                if data[n][i][3] == block[i][3]:\n",
        "                    upos +=1\n",
        "                if data[n][i][4] == block[i][4]:\n",
        "                    xpos +=1\n",
        "                if data[n][i][5] == block[i][5]:\n",
        "                    feats +=1\n",
        "                if data[n][i][6] == block[i][6]:\n",
        "                    head +=1\n",
        "                if data[n][i][7] == block[i][7]:\n",
        "                    deprel +=1\n",
        "    t_total = FORM_total + LEMMA_total + UPOS_total + XPOS_total + FEATS_total + HEAD_total + DEPREL_total\n",
        "    c_total = form + lemma + upos + xpos + feats + head + deprel\n",
        "    result = f'Form accuracy: {form/FORM_total}\\nLemma accuracy: {lemma/LEMMA_total}\\nUpos accuracy: {upos/UPOS_total}\\nXpos accuracy: {xpos/XPOS_total}\\nFeatures accuracy: {feats/FEATS_total}\\nHead accuracy: {head/HEAD_total}\\nDeprel accuracy: {deprel/DEPREL_total}\\nTotal accuracy: {c_total/t_total}\\n'\n",
        "    return result"
      ],
      "metadata": {
        "id": "j_PXd0ZNxU2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_conllu = \"test.conllu\"\n",
        "udpipe_conllu = \"udpipe.conllu\"\n",
        "\n",
        "print(compare_conllu_files(test_conllu, udpipe_conllu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNGRfMrD1TcO",
        "outputId": "b693be6b-6ddf-47e5-f200-807553e93e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Form accuracy: 0.007765216398309923\n",
            "Lemma accuracy: 0.008107799474705949\n",
            "Upos accuracy: 0.10106200753682767\n",
            "Xpos accuracy: 1.0\n",
            "Features accuracy: 0.11270983213429256\n",
            "Head accuracy: 0.17106314948041568\n",
            "Deprel accuracy: 0.06908758707319858\n",
            "Total accuracy: 0.2099707988711072\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_conllu = \"spacy.conllu\"\n",
        "\n",
        "print(compare_conllu_files(test_conllu, spacy_conllu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJDkjvfi1UGy",
        "outputId": "2862582a-3681-4167-9649-2b6769af094f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Form accuracy: 0.9142661179698217\n",
            "Lemma accuracy: 0.7906133646874388\n",
            "Upos accuracy: 0.8474426807760141\n",
            "Xpos accuracy: 0.0\n",
            "Features accuracy: 0.6344307270233196\n",
            "Head accuracy: 0.6972369194591417\n",
            "Deprel accuracy: 0.6917499510092102\n",
            "Total accuracy: 0.6536771087035638\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanza_conllu = \"stanza.conllu\"\n",
        "\n",
        "print(compare_conllu_files(test_conllu, stanza_conllu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQoZCHoy1U01",
        "outputId": "e38c5dc3-afdc-4bb6-9946-513f11eec64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Form accuracy: 0.9117589512815496\n",
            "Lemma accuracy: 0.8547251027196243\n",
            "Upos accuracy: 0.880747407552338\n",
            "Xpos accuracy: 0.0\n",
            "Features accuracy: 0.7555272940716102\n",
            "Head accuracy: 0.7359616513402465\n",
            "Deprel accuracy: 0.7945607513206809\n",
            "Total accuracy: 0.7047544511837214\n",
            "\n"
          ]
        }
      ]
    }
  ]
}